{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hurricane195/Intro-to-Deep-Learning/blob/Homework_5/HW5_P2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXJ7QOmqv1p9"
      },
      "source": [
        "Like Homework 3. Problem 2, Build a transformer mode, for the tiny Shakespeare dataset, the data loader code is already provided.\n",
        "\n",
        "1. **Train the models for the sequence of 20 and 30, report and compare training loss, validation accuracy, execution time for training, and computational and mode size complexities, and compare it against RNN-based models.**\n",
        "\n",
        "2. Adjust the hyperparameters (number of layers, hidden size, and the number of heads) and compare your results (training and validation loss, computation complexity, model size, training and inference time, and the output sequence). Analyze their influence on accuracy, running time, and computational perplexity.\n",
        "\n",
        "3. What if we increase the sequence length to 50. Perform the training and report the accuracy and model complexity results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC4eRxw1vpcG"
      },
      "outputs": [],
      "source": [
        "#Using a modided example of Dr. Tabkhi's \"RNN\" available at https://github.com/HamedTabkhi/Intro-to-DL/blob/main/RNN.py\n",
        "#Using a modided example of Dr. Tabkhi's \"RNN-CharDataset\" available at https://github.com/HamedTabkhi/Intro-to-DL/blob/main/RNN-CharDataset.py\n",
        "#Using a modided example of Dr. Tabkhi's \"shakespeare-loader.py\" available at https://github.com/HamedTabkhi/Intro-to-DL/blob/main/shakespeare-loader.py\n",
        "#Using a modided example of Dr. Tabkhi's \"transformer_encoder_nextcharactor\" available at https://github.com/HamedTabkhi/Intro-to-DL/blob/main/transformer_encoder_nextcharactor.py\n",
        "#Random help from Chat GPT on formatting, sytntax, etc.\n",
        "#Random help from Chat Colab AI on formatting, sytntax, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsIqPri1TA1l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "199KcmHMx1vo",
        "outputId": "4ae53a8e-c5f5-4e30-aaeb-f68d7b8561c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Check for CUDA support and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E-V7pjorX53"
      },
      "outputs": [],
      "source": [
        "#Download the dataset\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text  # This is the entire text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAxQQGCMsM4t"
      },
      "source": [
        "**MAXIMUM LENGTH OF INPUT SECQUENCES = 20**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty3Ss4JVrdV_"
      },
      "outputs": [],
      "source": [
        "#Prepare the dataset\n",
        "sequence_length = 20\n",
        "# Create a character mapping to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIuvc0zPrhzj"
      },
      "outputs": [],
      "source": [
        "# Encode the text into integers\n",
        "encoded_text = [char_to_int[ch] for ch in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4EWMpZRrkcR"
      },
      "outputs": [],
      "source": [
        "# Create sequences and targets\n",
        "sequences = []\n",
        "targets = []\n",
        "for i in range(0, len(encoded_text) - sequence_length):\n",
        "    seq = encoded_text[i:i+sequence_length]\n",
        "    target = encoded_text[i+sequence_length]\n",
        "    sequences.append(seq)\n",
        "    targets.append(target)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "targets = np.array(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-updB7piHC6"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(sequences, targets, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofrCzO7QilqM"
      },
      "outputs": [],
      "source": [
        "# Converting data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot47W5O6rpVt"
      },
      "outputs": [],
      "source": [
        "#Create a dataset class\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaYFkmSkrwPN"
      },
      "outputs": [],
      "source": [
        "# Create datasets and data loaders\n",
        "batch_size = 128\n",
        "train_dataset = CharDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = CharDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37fojvqSTe_7"
      },
      "outputs": [],
      "source": [
        "# Defining the Transformer model\n",
        "class CharTransformer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, nhead):\n",
        "        super(CharTransformer, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(hidden_size, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        transformer_output = self.transformer_encoder(embedded)\n",
        "        output = self.fc(transformer_output[:, -1, :])  # Get the output of the last Transformer block\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td4AGgC2TiHl"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 128\n",
        "num_layers = 3\n",
        "nhead = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08mM2r-QTkFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b39a3f1-fd04-4596-b03a-9e30d3d00b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "# Model, loss, and optimizer\n",
        "model = CharTransformer(len(chars), hidden_size, len(chars), num_layers, nhead)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3IEg0wRqCC1",
        "outputId": "24de8d18-883c-40bf-ed9a-4fdfc2438dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1795777"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#count trainable parameters of the model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqpBZgkwUXuf",
        "outputId": "481d5c28-fa06-4944-d307-7596d5d4e6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 2.5166, Training Accuracy: 0.2608, Validation Loss: 2.4869, Validation Accuracy: 0.2684\n",
            "Epoch 2/10, Training Loss: 2.4855, Training Accuracy: 0.2658, Validation Loss: 2.4731, Validation Accuracy: 0.2685\n",
            "Epoch 3/10, Training Loss: 2.4809, Training Accuracy: 0.2666, Validation Loss: 2.4687, Validation Accuracy: 0.2659\n",
            "Epoch 4/10, Training Loss: 2.4764, Training Accuracy: 0.2677, Validation Loss: 2.4671, Validation Accuracy: 0.2639\n",
            "Epoch 5/10, Training Loss: 2.4745, Training Accuracy: 0.2677, Validation Loss: 2.4657, Validation Accuracy: 0.2697\n",
            "Epoch 6/10, Training Loss: 2.4723, Training Accuracy: 0.2683, Validation Loss: 2.4646, Validation Accuracy: 0.2677\n",
            "Epoch 7/10, Training Loss: 2.4704, Training Accuracy: 0.2688, Validation Loss: 2.4634, Validation Accuracy: 0.2697\n",
            "Epoch 8/10, Training Loss: 2.4725, Training Accuracy: 0.2687, Validation Loss: 2.4632, Validation Accuracy: 0.2682\n",
            "Epoch 9/10, Training Loss: 2.4702, Training Accuracy: 0.2688, Validation Loss: 2.4639, Validation Accuracy: 0.2682\n",
            "Epoch 10/10, Training Loss: 2.4723, Training Accuracy: 0.2683, Validation Loss: 2.4628, Validation Accuracy: 0.2697\n",
            "Training time: 7247.609557628632 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "    train_accuracy = correct / total\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            val_output = model(batch_X)\n",
        "            val_loss = criterion(val_output, batch_y)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(val_output.data, 1)\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "    val_accuracy = correct / total\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    \"\"\"\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    \"\"\"\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tb1RaHkUa70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e8b34e-2e1a-4b48-d7b8-6c5b00bd14b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FIRST TEST STRING: This is a simple example to demonstrate how to predict the next char..\n",
            "First predicted next character: 'e'\n",
            "\n",
            "SECOND TEST STRING: Long live the quee..\n",
            "Second predicted next character: ' '\n",
            "\n",
            "THIRD TEST STRING: Be quiet and do not spea..\n",
            "Third predicted next character: 'n'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prediction function\n",
        "def predict_next_char(model, char_to_int, int_to_char, initial_str):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        initial_input = torch.tensor([char_to_int[c] for c in initial_str[-sequence_length:]], dtype=torch.long).unsqueeze(0)\n",
        "        prediction = model(initial_input)\n",
        "        predicted_index = torch.argmax(prediction, dim=1).item()\n",
        "        return int_to_char[predicted_index]\n",
        "\n",
        "# Predicting the first next character\n",
        "test_str = \"This is a simple example to demonstrate how to predict the next char\"\n",
        "predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str)\n",
        "print('FIRST TEST STRING: This is a simple example to demonstrate how to predict the next char..')\n",
        "print(f\"First predicted next character: '{predicted_char}'\")\n",
        "print(\"\")\n",
        "\n",
        "# Predicting the second next character\n",
        "test_str = \"Long live the quee\"\n",
        "predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str)\n",
        "print('SECOND TEST STRING: Long live the quee..')\n",
        "print(f\"Second predicted next character: '{predicted_char}'\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# Predicting the third next character\n",
        "test_str = \"Be quiet and do not spea\"\n",
        "predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str)\n",
        "print('THIRD TEST STRING: Be quiet and do not spea..')\n",
        "print(f\"Third predicted next character: '{predicted_char}'\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uO-f-zXsWC-"
      },
      "source": [
        "**MAXIMUM LENGTH OF INPUT SECQUENCES = 30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT-Fx3EDscAz"
      },
      "outputs": [],
      "source": [
        "#Prepare the dataset\n",
        "sequence_length = 30\n",
        "# Create a character mapping to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7RnXSn6tgJ2"
      },
      "outputs": [],
      "source": [
        "# Encode the text into integers\n",
        "encoded_text = [char_to_int[ch] for ch in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UpehoKotivU"
      },
      "outputs": [],
      "source": [
        "# Create sequences and targets\n",
        "sequences = []\n",
        "targets = []\n",
        "for i in range(0, len(encoded_text) - sequence_length):\n",
        "    seq = encoded_text[i:i+sequence_length]\n",
        "    target = encoded_text[i+sequence_length]\n",
        "    sequences.append(seq)\n",
        "    targets.append(target)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "targets = np.array(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC4fSsNWhavB"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(sequences, targets, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWkNO_tJhbg5"
      },
      "outputs": [],
      "source": [
        "# Converting data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plh3CGythgFH"
      },
      "outputs": [],
      "source": [
        "#Create a dataset class\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and data loaders\n",
        "batch_size = 128\n",
        "train_dataset = CharDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = CharDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "M0K-d8mdSOpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_J-3wq4tw3Q"
      },
      "outputs": [],
      "source": [
        "# Defining the Transformer model\n",
        "class CharTransformer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, nhead):\n",
        "        super(CharTransformer, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(hidden_size, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        transformer_output = self.transformer_encoder(embedded)\n",
        "        output = self.fc(transformer_output[:, -1, :])  # Get the output of the last Transformer block\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKBQ7FyatxpW"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 128\n",
        "num_layers = 3\n",
        "nhead = 2\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0thu2bGnt0tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1ef520-aadd-463a-e45b-6c9f53914ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "# Model, loss, and optimizer\n",
        "model = CharTransformer(len(chars), hidden_size, len(chars), num_layers, nhead)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3chkidUDqHCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7e8925-6cf3-4052-8f9c-5e194c55e409"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1795777"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#count trainable parameters of the model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZVR82dQt5CS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ade241a-165d-4352-af96-5790ef550e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 2.5161, Training Accuracy: 0.2607, Validation Loss: 2.5102, Validation Accuracy: 0.2642\n",
            "Epoch 2/10, Training Loss: 2.4873, Training Accuracy: 0.2649, Validation Loss: 2.4790, Validation Accuracy: 0.2709\n",
            "Epoch 3/10, Training Loss: 2.4790, Training Accuracy: 0.2669, Validation Loss: 2.4714, Validation Accuracy: 0.2700\n",
            "Epoch 4/10, Training Loss: 2.4779, Training Accuracy: 0.2673, Validation Loss: 2.4711, Validation Accuracy: 0.2700\n",
            "Epoch 5/10, Training Loss: 2.4731, Training Accuracy: 0.2682, Validation Loss: 2.4714, Validation Accuracy: 0.2712\n",
            "Epoch 6/10, Training Loss: 2.4713, Training Accuracy: 0.2683, Validation Loss: 2.4671, Validation Accuracy: 0.2713\n",
            "Epoch 7/10, Training Loss: 2.4737, Training Accuracy: 0.2680, Validation Loss: 2.4657, Validation Accuracy: 0.2697\n",
            "Epoch 8/10, Training Loss: 2.4729, Training Accuracy: 0.2682, Validation Loss: 2.4647, Validation Accuracy: 0.2706\n",
            "Epoch 9/10, Training Loss: 2.4706, Training Accuracy: 0.2686, Validation Loss: 2.4641, Validation Accuracy: 0.2700\n",
            "Epoch 10/10, Training Loss: 2.4722, Training Accuracy: 0.2685, Validation Loss: 2.4647, Validation Accuracy: 0.2713\n",
            "Training time: 10375.484166622162 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "    train_accuracy = correct / total\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            val_output = model(batch_X)\n",
        "            val_loss = criterion(val_output, batch_y)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(val_output.data, 1)\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "    val_accuracy = correct / total\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    \"\"\"\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    \"\"\"\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TBIVAxrt77O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e3ba71e-ff91-4722-b456-606ea1997643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FIRST TEST STRING: This is a simple example to demonstrate how to predict the next char..\n",
            "First predicted next character: 'n'\n",
            "\n",
            "SECOND TEST STRING: Long live the quee..\n",
            "Second predicted next character: ' '\n",
            "\n",
            "THIRD TEST STRING: Be quiet and do not spea..\n",
            "Third predicted next character: 'o'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prediction function\n",
        "def predict_next_char(model, char_to_int, int_to_char, initial_str):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        initial_input = torch.tensor([char_to_int[c] for c in initial_str[-sequence_length:]], dtype=torch.long).unsqueeze(0)\n",
        "        prediction = model(initial_input)\n",
        "        predicted_index = torch.argmax(prediction, dim=1).item()\n",
        "        return int_to_char[predicted_index]\n",
        "\n",
        "# Predicting the first next character\n",
        "test_str = \"This is a simple example to demonstrate how to predict the next char\"\n",
        "predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str)\n",
        "print('FIRST TEST STRING: This is a simple example to demonstrate how to predict the next char..')\n",
        "print(f\"First predicted next character: '{predicted_char}'\")\n",
        "print(\"\")\n",
        "\n",
        "# Predicting the second next character\n",
        "test_str = \"Long live the quee\"\n",
        "predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str)\n",
        "print('SECOND TEST STRING: Long live the quee..')\n",
        "print(f\"Second predicted next character: '{predicted_char}'\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# Predicting the third next character\n",
        "test_str = \"Be quiet and do not spea\"\n",
        "predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str)\n",
        "print('THIRD TEST STRING: Be quiet and do not spea..')\n",
        "print(f\"Third predicted next character: '{predicted_char}'\")\n",
        "print(\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}